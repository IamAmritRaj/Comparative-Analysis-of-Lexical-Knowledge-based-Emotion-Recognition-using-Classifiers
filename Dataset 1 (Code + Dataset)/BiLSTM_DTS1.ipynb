{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c84f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e3305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweet_emotions2.csv\", encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca6ebdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74787</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@MichelGW have you gift! Hope you like it! It'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74788</th>\n",
       "      <td>joy</td>\n",
       "      <td>The world didnt give it to me..so the world MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74789</th>\n",
       "      <td>anger</td>\n",
       "      <td>A man robbed me today .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74790</th>\n",
       "      <td>fear</td>\n",
       "      <td>Youu call it JEALOUSY, I call it of #Losing YO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74791</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I think about you baby, and I dream about you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74792 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                            content\n",
       "0           empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1         sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2         sadness                Funeral ceremony...gloomy friday...\n",
       "3      enthusiasm               wants to hang out with friends SOON!\n",
       "4         neutral  @dannycastillo We want to trade with someone w...\n",
       "...           ...                                                ...\n",
       "74787    surprise  @MichelGW have you gift! Hope you like it! It'...\n",
       "74788         joy  The world didnt give it to me..so the world MO...\n",
       "74789       anger                           A man robbed me today . \n",
       "74790        fear  Youu call it JEALOUSY, I call it of #Losing YO...\n",
       "74791     sadness  I think about you baby, and I dream about you ...\n",
       "\n",
       "[74792 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93381262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_tokenized_lemmatized(tweet):\n",
    "    tweet = tweet.lower()                                                       #converting the text into lower\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)                                          #removing @mentions\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)                                          #removing hashtags\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)   #removing url          \n",
    "    tweet = re.sub(r'[^\\w\\s]','',tweet)                                         #removing punctuations\n",
    "    tweet = re.sub(r'\\d+', '', tweet)                                           #removing numbers\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet).strip()                                  #removing extra whitespaces  \n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stops = stopwords.words('english')\n",
    "    \n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    tokens = [t for t in tokens if not t in stops]\n",
    "    fintokens = []\n",
    "    for token in tokens:\n",
    "        fintokens.append(lemmatizer.lemmatize(token))\n",
    "    finaltext = \" \"\n",
    "    return finaltext.join(fintokens)\n",
    "\n",
    "for i in df.index:\n",
    "    string = df['content'][i]\n",
    "    preprostr = clean_tokenized_lemmatized(string)\n",
    "    df.at[i, 'content'] = preprostr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b93fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0878b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_sentiment = LabelEncoder()\n",
    "df['Label'] = le_sentiment.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa309a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    11887\n",
       "9     11045\n",
       "11    10892\n",
       "16     8459\n",
       "15     6249\n",
       "5      5410\n",
       "7      5209\n",
       "0      4407\n",
       "10     3842\n",
       "6      1776\n",
       "12     1526\n",
       "8      1323\n",
       "2       856\n",
       "3       827\n",
       "4       759\n",
       "1       179\n",
       "14      146\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03dd61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26b1fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df['content'])\n",
    "max_length = 100\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccfb6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90ec1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(padded_sequences))\n",
    "train_sequences = padded_sequences[:train_size]\n",
    "train_labels = labels[:train_size]\n",
    "val_sequences = padded_sequences[train_size:train_size+1000]\n",
    "val_labels = labels[train_size:train_size+1000]\n",
    "test_sequences = padded_sequences[train_size+1000:]\n",
    "test_labels = labels[train_size+1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c42a9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(5000, 32, input_length=max_length),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(17, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95b0b06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1870/1870 [==============================] - 121s 63ms/step - loss: 2.2670 - accuracy: 0.2549 - val_loss: 1.7800 - val_accuracy: 0.4560\n",
      "Epoch 2/10\n",
      "1870/1870 [==============================] - 112s 60ms/step - loss: 1.9726 - accuracy: 0.3667 - val_loss: 1.5514 - val_accuracy: 0.5150\n",
      "Epoch 3/10\n",
      "1870/1870 [==============================] - 117s 63ms/step - loss: 1.8804 - accuracy: 0.3968 - val_loss: 1.6428 - val_accuracy: 0.4920\n",
      "Epoch 4/10\n",
      "1870/1870 [==============================] - 120s 64ms/step - loss: 1.8250 - accuracy: 0.4114 - val_loss: 1.5784 - val_accuracy: 0.5090\n",
      "Epoch 5/10\n",
      "1870/1870 [==============================] - 120s 64ms/step - loss: 1.7745 - accuracy: 0.4239 - val_loss: 1.5863 - val_accuracy: 0.5110\n",
      "Epoch 6/10\n",
      "1870/1870 [==============================] - 120s 64ms/step - loss: 1.7337 - accuracy: 0.4377 - val_loss: 1.6226 - val_accuracy: 0.5020\n",
      "Epoch 7/10\n",
      "1870/1870 [==============================] - 122s 65ms/step - loss: 1.6887 - accuracy: 0.4528 - val_loss: 1.6899 - val_accuracy: 0.4860\n",
      "Epoch 8/10\n",
      "1870/1870 [==============================] - 123s 66ms/step - loss: 1.6487 - accuracy: 0.4667 - val_loss: 1.7666 - val_accuracy: 0.4670\n",
      "Epoch 9/10\n",
      "1870/1870 [==============================] - 126s 67ms/step - loss: 1.6094 - accuracy: 0.4784 - val_loss: 1.8437 - val_accuracy: 0.4760\n",
      "Epoch 10/10\n",
      "1870/1870 [==============================] - 131s 70ms/step - loss: 1.5728 - accuracy: 0.4890 - val_loss: 1.8536 - val_accuracy: 0.4970\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(train_sequences, train_labels, validation_data=(val_sequences, val_labels), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9449c09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437/437 [==============================] - 12s 27ms/step - loss: 1.8660 - accuracy: 0.4962\n",
      "Test Loss: 1.8659764528274536\n",
      "Test Accuracy: 0.4961673617362976\n",
      "437/437 [==============================] - 13s 27ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.48      0.54      1685\n",
      "           2       0.46      0.03      0.06       326\n",
      "           5       0.75      0.56      0.65      2177\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.67      0.51      0.58      4412\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.35      0.76      0.48       907\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.57      0.47      0.52      2774\n",
      "          14       0.91      0.68      0.78        57\n",
      "          15       0.54      0.36      0.43      1621\n",
      "          16       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50     13959\n",
      "   macro avg       0.37      0.30      0.31     13959\n",
      "weighted avg       0.62      0.50      0.54     13959\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_sequences = padded_sequences[train_size+1000:]\n",
    "test_labels = labels[train_size+1000:]\n",
    "test_loss, test_acc = model.evaluate(test_sequences, test_labels)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)\n",
    "\n",
    "y_pred = model.predict(test_sequences)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "report = classification_report(test_labels, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e6f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
