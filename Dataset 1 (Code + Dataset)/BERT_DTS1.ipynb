{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f539c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3078be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding,LSTM ,Conv1D, MaxPool1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c62370",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ac5f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"tweet_emotions2.csv\", encoding=\"iso-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebca575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74787</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@MichelGW have you gift! Hope you like it! It'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74788</th>\n",
       "      <td>joy</td>\n",
       "      <td>The world didnt give it to me..so the world MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74789</th>\n",
       "      <td>anger</td>\n",
       "      <td>A man robbed me today .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74790</th>\n",
       "      <td>fear</td>\n",
       "      <td>Youu call it JEALOUSY, I call it of #Losing YO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74791</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I think about you baby, and I dream about you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                            content\n",
       "0           empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1         sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2         sadness                Funeral ceremony...gloomy friday...\n",
       "3      enthusiasm               wants to hang out with friends SOON!\n",
       "4         neutral  @dannycastillo We want to trade with someone w...\n",
       "...           ...                                                ...\n",
       "74787    surprise  @MichelGW have you gift! Hope you like it! It'...\n",
       "74788         joy  The world didnt give it to me..so the world MO...\n",
       "74789       anger                           A man robbed me today . \n",
       "74790        fear  Youu call it JEALOUSY, I call it of #Losing YO...\n",
       "74791     sadness  I think about you baby, and I dream about you ...\n",
       "\n",
       "[74792 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62275c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f9c891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.5.2-cp311-cp311-macosx_10_9_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp311-cp311-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp311-cp311-macosx_10_9_x86_64.whl (31 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp311-cp311-macosx_10_9_x86_64.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.9-cp311-cp311-macosx_10_9_x86_64.whl (848 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.2/848.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp311-cp311-macosx_10_9_x86_64.whl (489 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.1/489.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.28.2)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.7-cp311-cp311-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp311-cp311-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy) (2.1.2)\n",
      "Installing collected packages: cymem, wasabi, typer, spacy-loggers, spacy-legacy, smart-open, pydantic, murmurhash, langcodes, catalogue, blis, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.7 smart-open-6.3.0 spacy-3.5.2 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.9 typer-0.7.0 wasabi-1.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b9df00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy==2.2.3\n",
      "  Using cached spacy-2.2.3.tar.gz (5.9 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[56 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/_vendor/packaging/requirements.py\", line 35, in __init__\n",
      "  \u001b[31m   \u001b[0m     parsed = parse_requirement(requirement_string)\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 64, in parse_requirement\n",
      "  \u001b[31m   \u001b[0m     return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 82, in _parse_requirement\n",
      "  \u001b[31m   \u001b[0m     url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 126, in _parse_requirement_details\n",
      "  \u001b[31m   \u001b[0m     marker = _parse_requirement_marker(\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 147, in _parse_requirement_marker\n",
      "  \u001b[31m   \u001b[0m     tokenizer.raise_syntax_error(\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/_vendor/packaging/_tokenizer.py\", line 163, in raise_syntax_error\n",
      "  \u001b[31m   \u001b[0m     raise ParserSyntaxError(\n",
      "  \u001b[31m   \u001b[0m setuptools.extern.packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after version specifier)\n",
      "  \u001b[31m   \u001b[0m     spacy_lookups_data>=0.0.5<0.2.0\n",
      "  \u001b[31m   \u001b[0m                       ~~~~~~~^\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 351, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 333, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 341, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 323, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 338, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 200, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 190, in setup_package\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/__init__.py\", line 106, in setup\n",
      "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/__init__.py\", line 77, in _install_setup_requires\n",
      "  \u001b[31m   \u001b[0m     dist.parse_config_files(ignore_option_errors=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/dist.py\", line 910, in parse_config_files\n",
      "  \u001b[31m   \u001b[0m     self._finalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/dist.py\", line 606, in _finalize_requires\n",
      "  \u001b[31m   \u001b[0m     self._convert_extras_requirements()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/dist.py\", line 621, in _convert_extras_requirements\n",
      "  \u001b[31m   \u001b[0m     for r in _reqs.parse(v):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wc/mp4q08y969769yrr58t6frhc0000gn/T/pip-build-env-dcpwbsvq/overlay/lib/python3.11/site-packages/setuptools/_vendor/packaging/requirements.py\", line 37, in __init__\n",
      "  \u001b[31m   \u001b[0m     raise InvalidRequirement(str(e)) from e\n",
      "  \u001b[31m   \u001b[0m setuptools.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after version specifier)\n",
      "  \u001b[31m   \u001b[0m     spacy_lookups_data>=0.0.5<0.2.0\n",
      "  \u001b[31m   \u001b[0m                       ~~~~~~~^\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[?25hzsh:1: command not found: python\n",
      "Requirement already satisfied: beautifulsoup4==4.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4==4.9.1) (2.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: textblob==0.15.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textblob==0.15.3) (3.8.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.1->textblob==0.15.3) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.1->textblob==0.15.3) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.1->textblob==0.15.3) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.1->textblob==0.15.3) (4.64.1)\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy==2.2.3\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install beautifulsoup4==4.9.1\n",
    "!pip install textblob==0.15.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "089381fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Requirement 'en_core_web_sm-3.1.0-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing ./en_core_web_sm-3.1.0-py3-none-any.whl\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/Users/amritraj/Downloads/en_core_web_sm-3.1.0-py3-none-any.whl'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install en_core_web_sm-3.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89baa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4a9fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from keras.models import Model\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate, Dropout,LeakyReLU\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Input, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import InputLayer, Conv1D, Dense, Flatten, MaxPooling1D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6482884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "  Downloading ktrain-0.36.0.tar.gz (25.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m732.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ktrain) (1.2.2)\n",
      "Collecting matplotlib>=3.0.0\n",
      "  Using cached matplotlib-3.7.1-cp311-cp311-macosx_10_12_x86_64.whl (7.4 MB)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ktrain) (2.0.0)\n",
      "Collecting fastprogress>=0.1.21\n",
      "  Using cached fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ktrain) (2.28.2)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ktrain) (1.2.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ktrain) (23.1)\n",
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba\n",
      "  Using cached jieba-0.42.1.tar.gz (19.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cchardet\n",
      "  Using cached cchardet-2.1.7.tar.gz (653 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting chardet\n",
      "  Using cached chardet-5.1.0-py3-none-any.whl (199 kB)\n",
      "Collecting syntok>1.3.3\n",
      "  Using cached syntok-1.4.4-py3-none-any.whl (24 kB)\n",
      "Collecting tika\n",
      "  Using cached tika-2.6.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers>=4.17.0\n",
      "  Using cached transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.98-cp311-cp311-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "Collecting keras_bert>=0.86.0\n",
      "  Using cached keras-bert-0.89.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting whoosh\n",
      "  Using cached Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras_bert>=0.86.0->ktrain) (1.23.5)\n",
      "Collecting keras-transformer==0.40.0\n",
      "  Using cached keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-pos-embd==0.13.0\n",
      "  Using cached keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-multi-head==0.29.0\n",
      "  Using cached keras-multi-head-0.29.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-layer-normalization==0.16.0\n",
      "  Using cached keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-position-wise-feed-forward==0.8.0\n",
      "  Using cached keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-embed-sim==0.10.0\n",
      "  Using cached keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-self-attention==0.51.0\n",
      "  Using cached keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.7-cp311-cp311-macosx_10_9_x86_64.whl (244 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp311-cp311-macosx_10_9_x86_64.whl (65 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->ktrain) (9.3.0)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.0.1->ktrain) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.0.1->ktrain) (2023.3)\n",
      "Requirement already satisfied: regex>2016 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from syntok>1.3.3->ktrain) (2022.10.31)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-macosx_10_11_universal2.whl (4.0 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.17.0->ktrain) (4.64.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langdetect->ktrain) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ktrain) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ktrain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ktrain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ktrain) (2022.12.7)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->ktrain) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->ktrain) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tika->ktrain) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.17.0->ktrain) (4.5.0)\n",
      "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, cchardet, jieba, langdetect, tika\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ktrain: filename=ktrain-0.36.0-py3-none-any.whl size=25317508 sha256=85275ab9e5a09922b9a0608e6dca4c50d95fcb8d85d718a5486dc7e0d855a81b\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/5b/9d/47/3cb8ea805dd2312f38427731d84426220b48df84071bc94598\n",
      "  Building wheel for keras_bert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33501 sha256=1dbe0006b448e8b3ffbb45ede4674c5e29d3e83002ef6f97e2d8f0b0604362ea\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/60/98/89/f09103b721e977ea3f13dc45b6079be0186f1751f3861ef145\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12287 sha256=5bb9bbfcc63ccd8d80efd0a1e750a9fe9b47713c27bcf8a750db10da6a0c8ca3\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/a1/c2/da/ba656eca53f17c128ece3e57f7cdd9028f762561a78f4e6479\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3944 sha256=bf37a0c8a2317b06817f7519c0e7506aa76ce01789db481e4270db3ad20e27fe\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/fa/cd/34/8d92e811c8aa72163302842e0de4c7f7210b53b6c32f6f0874\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4655 sha256=005ef0f0e6d0e17d36706090c8de34e2b3e50877801794749ee413ec54387e12\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/9d/fd/bc/d09cdb539a3910cec46e29b3b604f9e6880b01cc2db356418c\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14979 sha256=4848e3e4b51e4dc0d21e3cfdeb606f25d0aecdbe7138a3c6f0b3a10fd12ce76e\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/f8/84/af/91ceeb8df1cb0205290bf193a3d883c64c613b445d4e807825\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6946 sha256=6df12b4550da3c7bbbe60873f4e16cda0c2ac342133b621d18cf1aa0743898c9\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/c6/af/ee/ddedabbf7c7e07612e8ed006097f78f5d8b024c8422bbcf551\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4968 sha256=2a7eaf6f2c85d588917a1201ff7e66f1fa38aed8331342eded19120f13c1e788\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/4d/c5/9e/06bdb12c76c1b99b82054db06e52c3f3b23bea639ec39182b3\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18892 sha256=43e4dffafd150d08ff7785fa2e5cff6d437fdd165e8ed1c5c938042195921dc3\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/0e/d5/84/78c085760ee12f6c1b7be1c1e81f87f8d07287ba1773d7e4ee\n",
      "  Building wheel for cchardet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cchardet: filename=cchardet-2.1.7-cp311-cp311-macosx_10_9_universal2.whl size=227809 sha256=5db318611a7673ce5eff91dc9dc86ee6075551bef4f2e8a4c4761aa86c09205c\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/17/bc/05/ef28935c7d9d6fd9d60d41972010b40841e17f3dcc228804e5\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=0d1e868d844791e73530f02ea3b4b5ece4c4c8722820da83ebce2724d840790d\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/9e/e1/e6/a79f6806b13624bde86455ca13b7ea62f5ab0cd789ba1e8535\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=a266bdf1286598b5500df98681e327b9d75ffd63ad0e461bdd81176e5f677133\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/82/db/43/cb54039c7e77322827cbefaa8caccdfa43daad323801c138f4\n",
      "  Building wheel for tika (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32625 sha256=69efece34bdd102966325211c6eb254bc169a16a3aef91dc095f4b3b334708ac\n",
      "  Stored in directory: /Users/amritraj/Library/Caches/pip/wheels/de/97/f2/81fe281f82ce4e9a20c60ee94288624e2f128dd9629ea44a4b\n",
      "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention cchardet jieba langdetect tika\n",
      "Installing collected packages: whoosh, tokenizers, sentencepiece, jieba, cchardet, syntok, pyparsing, langdetect, kiwisolver, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, fonttools, filelock, fastprogress, cycler, contourpy, chardet, tika, matplotlib, keras-multi-head, huggingface-hub, transformers, keras-transformer, keras_bert, ktrain\n",
      "Successfully installed cchardet-2.1.7 chardet-5.1.0 contourpy-1.0.7 cycler-0.11.0 fastprogress-1.0.3 filelock-3.12.0 fonttools-4.39.3 huggingface-hub-0.13.4 jieba-0.42.1 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 kiwisolver-1.4.4 ktrain-0.36.0 langdetect-1.0.9 matplotlib-3.7.1 pyparsing-3.0.9 sentencepiece-0.1.98 syntok-1.4.4 tika-2.6.0 tokenizers-0.13.3 transformers-4.28.1 whoosh-2.7.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b522cc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ktrain\n",
    "import tensorflow as tf\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8745faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {'sadness': 0, 'joy': 1, 'neutral': 2,'worry':3, 'surprise': 4,'fear':5, 'happiness':6,'anger': 7,'anger': 8, 'love':9,'fun':10,'relief':11,'hate':12,'disgust':13,'empty':14,'enthusiasm':15,'boredom':16,\"shame\":17}\n",
    "\n",
    "df['sentiment'] = df['sentiment'].replace(sentiment_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90c4ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f93cc35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df['sentiment'] = encoder.fit_transform(df['sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b85475ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=df['content']\n",
    "Label=df['sentiment'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9325f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df.sample(n=5000, random_state=0)   \n",
    "testing_data = df.drop(train_data.index).sample(n=1000, random_state=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "073c986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentiment_0', 'sentiment_1', 'sentiment_2', 'sentiment_3', 'sentiment_4', 'sentiment_5', 'sentiment_6', 'sentiment_7', 'sentiment_8', 'sentiment_9', 'sentiment_10', 'sentiment_11', 'sentiment_12', 'sentiment_13', 'sentiment_14', 'sentiment_15', 'sentiment_16']\n",
      "       sentiment_0  sentiment_1  sentiment_2  sentiment_3  sentiment_4   \n",
      "64892          0.0          1.0          0.0          0.0          0.0  \\\n",
      "70907          0.0          0.0          1.0          0.0          0.0   \n",
      "44500          0.0          0.0          1.0          0.0          0.0   \n",
      "71137          0.0          0.0          0.0          0.0          0.0   \n",
      "70675          0.0          1.0          0.0          0.0          0.0   \n",
      "\n",
      "       sentiment_5  sentiment_6  sentiment_7  sentiment_8  sentiment_9   \n",
      "64892          0.0          0.0          0.0          0.0          0.0  \\\n",
      "70907          0.0          0.0          0.0          0.0          0.0   \n",
      "44500          0.0          0.0          0.0          0.0          0.0   \n",
      "71137          1.0          0.0          0.0          0.0          0.0   \n",
      "70675          0.0          0.0          0.0          0.0          0.0   \n",
      "\n",
      "       sentiment_10  sentiment_11  sentiment_12  sentiment_13  sentiment_14   \n",
      "64892           0.0           0.0           0.0           0.0           0.0  \\\n",
      "70907           0.0           0.0           0.0           0.0           0.0   \n",
      "44500           0.0           0.0           0.0           0.0           0.0   \n",
      "71137           0.0           0.0           0.0           0.0           0.0   \n",
      "70675           0.0           0.0           0.0           0.0           0.0   \n",
      "\n",
      "       sentiment_15  sentiment_16  \n",
      "64892           0.0           0.0  \n",
      "70907           0.0           0.0  \n",
      "44500           0.0           0.0  \n",
      "71137           0.0           0.0  \n",
      "70675           0.0           0.0  \n",
      "['sentiment_0', 'sentiment_1', 'sentiment_2', 'sentiment_3', 'sentiment_4', 'sentiment_5', 'sentiment_6', 'sentiment_7', 'sentiment_8', 'sentiment_9', 'sentiment_10', 'sentiment_11', 'sentiment_12', 'sentiment_13', 'sentiment_14', 'sentiment_15', 'sentiment_16']\n",
      "       sentiment_0  sentiment_1  sentiment_2  sentiment_3  sentiment_4   \n",
      "61244          1.0          0.0          0.0          0.0          0.0  \\\n",
      "12160          0.0          0.0          0.0          0.0          0.0   \n",
      "74360          0.0          1.0          0.0          0.0          0.0   \n",
      "63346          1.0          0.0          0.0          0.0          0.0   \n",
      "6908           0.0          0.0          0.0          1.0          0.0   \n",
      "\n",
      "       sentiment_5  sentiment_6  sentiment_7  sentiment_8  sentiment_9   \n",
      "61244          0.0          0.0          0.0          0.0          0.0  \\\n",
      "12160          0.0          0.0          0.0          0.0          0.0   \n",
      "74360          0.0          0.0          0.0          0.0          0.0   \n",
      "63346          0.0          0.0          0.0          0.0          0.0   \n",
      "6908           0.0          0.0          0.0          0.0          0.0   \n",
      "\n",
      "       sentiment_10  sentiment_11  sentiment_12  sentiment_13  sentiment_14   \n",
      "61244           0.0           0.0           0.0           0.0           0.0  \\\n",
      "12160           0.0           0.0           0.0           1.0           0.0   \n",
      "74360           0.0           0.0           0.0           0.0           0.0   \n",
      "63346           0.0           0.0           0.0           0.0           0.0   \n",
      "6908            0.0           0.0           0.0           0.0           0.0   \n",
      "\n",
      "       sentiment_15  sentiment_16  \n",
      "61244           0.0           0.0  \n",
      "12160           0.0           0.0  \n",
      "74360           0.0           0.0  \n",
      "63346           0.0           0.0  \n",
      "6908            0.0           0.0  \n",
      "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
      "[██████████████████████████████████████████████████]\n",
      "extracting pretrained BERT model...\n",
      "done.\n",
      "\n",
      "cleanup downloaded zip...\n",
      "done.\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test),preprocess=text.texts_from_df(train_df=training_data,text_column='content',label_columns='sentiment',\n",
    "                   val_df=testing_data,maxlen=400,preprocess_mode='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2523ceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "model=text.text_classifier(name='bert',train_data=(X_train,y_train),preproc=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecaa6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=ktrain.get_learner(model=model,train_data=(X_train,y_train),val_data=(X_test,y_test),batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91b39196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "834/834 [==============================] - 32606s 39s/step - loss: 2.2002 - accuracy: 0.2704 - val_loss: 1.8007 - val_accuracy: 0.4240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16caba990>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(lr=2e-5,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "269eaab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 560s 17s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 16, does not match size of target_names, 74792. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ktrain/core.py:203\u001b[0m, in \u001b[0;36mLearner.validate\u001b[0;34m(self, val_data, print_report, save_path, class_names)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprint_report\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     report \u001b[38;5;241m=\u001b[39m classification_report(\n\u001b[1;32m    211\u001b[0m         y_true, y_pred, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m print_report\n\u001b[1;32m    212\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2332\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2326\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2328\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2329\u001b[0m             )\n\u001b[1;32m   2330\u001b[0m         )\n\u001b[1;32m   2331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2336\u001b[0m         )\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2338\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 16, does not match size of target_names, 74792. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "learner.validate(val_data=(X_test, y_test), class_names=Label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "758b143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 616s 19s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 16, does not match size of target_names, 17. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m unique_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(training_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model as before\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Call the learner.validate() method with the labels parameter\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m _, acc \u001b[38;5;241m=\u001b[39m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Print the accuracy\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, acc)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ktrain/core.py:203\u001b[0m, in \u001b[0;36mLearner.validate\u001b[0;34m(self, val_data, print_report, save_path, class_names)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprint_report\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     report \u001b[38;5;241m=\u001b[39m classification_report(\n\u001b[1;32m    211\u001b[0m         y_true, y_pred, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m print_report\n\u001b[1;32m    212\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2332\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2326\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2328\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2329\u001b[0m             )\n\u001b[1;32m   2330\u001b[0m         )\n\u001b[1;32m   2331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2336\u001b[0m         )\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2338\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 16, does not match size of target_names, 17. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Get a list of all the unique labels in your dataset\n",
    "unique_labels = list(training_data['sentiment'].unique())\n",
    "\n",
    "# Train the model as before\n",
    "\n",
    "# Call the learner.validate() method with the labels parameter\n",
    "_, acc = learner.validate(val_data=(X_test, y_test), class_names=unique_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "369531d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 687s 22s/step\n",
      "Accuracy: 0.424\n",
      "Precision: 0.3883040262426729\n",
      "Recall: 0.424\n",
      "F1-score: 0.3933261833572164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_test_int = np.argmax(y_test, axis=1)\n",
    "\n",
    "y_pred = learner.model.predict(X_test)\n",
    "\n",
    "y_pred_int = np.argmax(y_pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test_int, y_pred_int)\n",
    "precision = precision_score(y_test_int, y_pred_int, average='weighted')\n",
    "recall = recall_score(y_test_int, y_pred_int, average='weighted')\n",
    "f1 = f1_score(y_test_int, y_pred_int, average='weighted')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52c9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
