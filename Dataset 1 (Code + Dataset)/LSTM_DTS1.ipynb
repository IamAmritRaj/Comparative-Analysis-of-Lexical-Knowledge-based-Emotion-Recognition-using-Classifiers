{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd1c032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74787</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@MichelGW have you gift! Hope you like it! It'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74788</th>\n",
       "      <td>joy</td>\n",
       "      <td>The world didnt give it to me..so the world MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74789</th>\n",
       "      <td>anger</td>\n",
       "      <td>A man robbed me today .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74790</th>\n",
       "      <td>fear</td>\n",
       "      <td>Youu call it JEALOUSY, I call it of #Losing YO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74791</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I think about you baby, and I dream about you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74792 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                            content\n",
       "0           empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1         sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2         sadness                Funeral ceremony...gloomy friday...\n",
       "3      enthusiasm               wants to hang out with friends SOON!\n",
       "4         neutral  @dannycastillo We want to trade with someone w...\n",
       "...           ...                                                ...\n",
       "74787    surprise  @MichelGW have you gift! Hope you like it! It'...\n",
       "74788         joy  The world didnt give it to me..so the world MO...\n",
       "74789       anger                           A man robbed me today . \n",
       "74790        fear  Youu call it JEALOUSY, I call it of #Losing YO...\n",
       "74791     sadness  I think about you baby, and I dream about you ...\n",
       "\n",
       "[74792 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"tweet_emotions2.csv\",encoding=\"latin\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d3e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n",
       "       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger',\n",
       "       'joy', 'fear', 'shame', 'disgust'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89bc5b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1870/1870 [==============================] - 670s 358ms/step - loss: 2.0604 - accuracy: 0.3179 - val_loss: 1.8389 - val_accuracy: 0.4051\n",
      "Epoch 2/10\n",
      "1870/1870 [==============================] - 1102s 590ms/step - loss: 1.6204 - accuracy: 0.4759 - val_loss: 1.7896 - val_accuracy: 0.4220\n",
      "Epoch 3/10\n",
      "1870/1870 [==============================] - 842s 450ms/step - loss: 1.2802 - accuracy: 0.5956 - val_loss: 1.8966 - val_accuracy: 0.4128\n",
      "Epoch 4/10\n",
      "1870/1870 [==============================] - 683s 365ms/step - loss: 0.9800 - accuracy: 0.6944 - val_loss: 2.0598 - val_accuracy: 0.4050\n",
      "Epoch 5/10\n",
      "1870/1870 [==============================] - 673s 360ms/step - loss: 0.7501 - accuracy: 0.7676 - val_loss: 2.2791 - val_accuracy: 0.3917\n",
      "Epoch 6/10\n",
      "1870/1870 [==============================] - 666s 356ms/step - loss: 0.6012 - accuracy: 0.8112 - val_loss: 2.4750 - val_accuracy: 0.3899\n",
      "Epoch 7/10\n",
      "1870/1870 [==============================] - 652s 348ms/step - loss: 0.5015 - accuracy: 0.8423 - val_loss: 2.6821 - val_accuracy: 0.3830\n",
      "Epoch 8/10\n",
      "1870/1870 [==============================] - 654s 350ms/step - loss: 0.4364 - accuracy: 0.8606 - val_loss: 2.8144 - val_accuracy: 0.3776\n",
      "Epoch 9/10\n",
      "1870/1870 [==============================] - 692s 370ms/step - loss: 0.3887 - accuracy: 0.8752 - val_loss: 3.0960 - val_accuracy: 0.3770\n",
      "Epoch 10/10\n",
      "1870/1870 [==============================] - 645s 345ms/step - loss: 0.3457 - accuracy: 0.8879 - val_loss: 3.2603 - val_accuracy: 0.3758\n",
      "468/468 [==============================] - 20s 41ms/step\n",
      "Accuracy: 0.3758272611805602\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.46      0.48       856\n",
      "           1       0.00      0.00      0.00        32\n",
      "           2       0.21      0.14      0.17       174\n",
      "           3       0.01      0.01      0.01       161\n",
      "           4       0.01      0.01      0.01       158\n",
      "           5       0.64      0.68      0.66      1073\n",
      "           6       0.07      0.06      0.06       382\n",
      "           7       0.25      0.28      0.26      1113\n",
      "           8       0.12      0.08      0.09       251\n",
      "           9       0.51      0.60      0.55      2194\n",
      "          10       0.29      0.22      0.25       732\n",
      "          11       0.35      0.44      0.39      2206\n",
      "          12       0.08      0.06      0.06       307\n",
      "          13       0.41      0.39      0.40      2340\n",
      "          14       0.97      0.82      0.89        38\n",
      "          15       0.36      0.24      0.29      1228\n",
      "          16       0.23      0.23      0.23      1714\n",
      "\n",
      "    accuracy                           0.38     14959\n",
      "   macro avg       0.30      0.28      0.28     14959\n",
      "weighted avg       0.37      0.38      0.37     14959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"tweet_emotions2.csv\",encoding=\"latin\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(subset=['content', 'sentiment'], inplace=True)\n",
    "\n",
    "# Prepare the data\n",
    "text = data['content'].astype(str).values\n",
    "labels = data['sentiment'].values\n",
    "\n",
    "# Encode labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "sequences = tokenizer.texts_to_sequences(text)\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=max_sequence_length))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc3547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
