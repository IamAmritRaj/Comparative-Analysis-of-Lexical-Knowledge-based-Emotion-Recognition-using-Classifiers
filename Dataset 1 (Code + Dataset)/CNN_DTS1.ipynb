{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fdb03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cdbca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweet_emotions2.csv\", encoding = \"latin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ca093e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74787</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@MichelGW have you gift! Hope you like it! It'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74788</th>\n",
       "      <td>joy</td>\n",
       "      <td>The world didnt give it to me..so the world MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74789</th>\n",
       "      <td>anger</td>\n",
       "      <td>A man robbed me today .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74790</th>\n",
       "      <td>fear</td>\n",
       "      <td>Youu call it JEALOUSY, I call it of #Losing YO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74791</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I think about you baby, and I dream about you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74792 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                            content\n",
       "0           empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1         sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2         sadness                Funeral ceremony...gloomy friday...\n",
       "3      enthusiasm               wants to hang out with friends SOON!\n",
       "4         neutral  @dannycastillo We want to trade with someone w...\n",
       "...           ...                                                ...\n",
       "74787    surprise  @MichelGW have you gift! Hope you like it! It'...\n",
       "74788         joy  The world didnt give it to me..so the world MO...\n",
       "74789       anger                           A man robbed me today . \n",
       "74790        fear  Youu call it JEALOUSY, I call it of #Losing YO...\n",
       "74791     sadness  I think about you baby, and I dream about you ...\n",
       "\n",
       "[74792 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d9b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_tokenized_lemmatized(tweet):\n",
    "    tweet = tweet.lower()                                                       #converting the text into lower\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)                                          #removing @mentions\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)                                          #removing hashtags\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)   #removing url          \n",
    "    tweet = re.sub(r'[^\\w\\s]','',tweet)                                         #removing punctuations\n",
    "    tweet = re.sub(r'\\d+', '', tweet)                                           #removing numbers\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet).strip()                                  #removing extra whitespaces  \n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stops = stopwords.words('english')\n",
    "    \n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    tokens = [t for t in tokens if not t in stops]\n",
    "    fintokens = []\n",
    "    for token in tokens:\n",
    "        fintokens.append(lemmatizer.lemmatize(token))\n",
    "    finaltext = \" \"\n",
    "    return finaltext.join(fintokens)\n",
    "\n",
    "for i in df.index:\n",
    "    string = df['content'][i]\n",
    "    preprostr = clean_tokenized_lemmatized(string)\n",
    "    df.at[i, 'content'] = preprostr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8833fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ec05df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_sentiment = LabelEncoder()\n",
    "df['label'] = le_sentiment.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e172b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    11887\n",
       "9     11045\n",
       "11    10892\n",
       "16     8459\n",
       "15     6249\n",
       "5      5410\n",
       "7      5209\n",
       "0      4407\n",
       "10     3842\n",
       "6      1776\n",
       "12     1526\n",
       "8      1323\n",
       "2       856\n",
       "3       827\n",
       "4       759\n",
       "1       179\n",
       "14      146\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e441e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"content\"], df[\"label\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "711a1655",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99488256",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45bd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 50\n",
    "train_padded = pad_sequences(train_sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=maxlen, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2a80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 17\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edb45d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=50, input_length=maxlen),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d7405e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11498f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1870/1870 [==============================] - 43s 21ms/step - loss: 2.3432 - accuracy: 0.2062 - val_loss: 2.1786 - val_accuracy: 0.2834\n",
      "Epoch 2/10\n",
      "1870/1870 [==============================] - 39s 21ms/step - loss: 2.1329 - accuracy: 0.2968 - val_loss: 2.0910 - val_accuracy: 0.3145\n",
      "Epoch 3/10\n",
      "1870/1870 [==============================] - 37s 20ms/step - loss: 2.0431 - accuracy: 0.3305 - val_loss: 2.0347 - val_accuracy: 0.3379\n",
      "Epoch 4/10\n",
      "1870/1870 [==============================] - 38s 20ms/step - loss: 1.9748 - accuracy: 0.3554 - val_loss: 2.0004 - val_accuracy: 0.3521\n",
      "Epoch 5/10\n",
      "1870/1870 [==============================] - 38s 20ms/step - loss: 1.9317 - accuracy: 0.3723 - val_loss: 1.9886 - val_accuracy: 0.3536\n",
      "Epoch 6/10\n",
      "1870/1870 [==============================] - 36s 19ms/step - loss: 1.8883 - accuracy: 0.3917 - val_loss: 1.9579 - val_accuracy: 0.3641\n",
      "Epoch 7/10\n",
      "1870/1870 [==============================] - 36s 19ms/step - loss: 1.8571 - accuracy: 0.4014 - val_loss: 1.9663 - val_accuracy: 0.3652\n",
      "Epoch 8/10\n",
      "1870/1870 [==============================] - 38s 20ms/step - loss: 1.8328 - accuracy: 0.4113 - val_loss: 1.9615 - val_accuracy: 0.3633\n",
      "Epoch 9/10\n",
      "1870/1870 [==============================] - 38s 20ms/step - loss: 1.8088 - accuracy: 0.4184 - val_loss: 1.9455 - val_accuracy: 0.3708\n",
      "Epoch 10/10\n",
      "1870/1870 [==============================] - 37s 20ms/step - loss: 1.7893 - accuracy: 0.4249 - val_loss: 1.9621 - val_accuracy: 0.3649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ebe974bfa0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_padded, train_labels, epochs=10, batch_size=32, validation_data=(test_padded, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20d75936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 2s 5ms/step - loss: 1.9621 - accuracy: 0.3649\n",
      "Test loss: 1.9621154069900513\n",
      "Test accuracy: 0.36486396193504333\n",
      "468/468 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.44       921\n",
      "           1       0.00      0.00      0.00        42\n",
      "           2       0.00      0.00      0.00       148\n",
      "           3       0.00      0.00      0.00       175\n",
      "           4       0.00      0.00      0.00       158\n",
      "           5       0.81      0.50      0.62      1129\n",
      "           6       0.00      0.00      0.00       344\n",
      "           7       0.24      0.31      0.27      1035\n",
      "           8       0.00      0.00      0.00       287\n",
      "           9       0.40      0.62      0.49      2210\n",
      "          10       0.00      0.00      0.00       788\n",
      "          11       0.29      0.62      0.40      2150\n",
      "          12       0.00      0.00      0.00       322\n",
      "          13       0.40      0.42      0.41      2396\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.86      0.13      0.23      1205\n",
      "          16       0.22      0.21      0.21      1619\n",
      "\n",
      "    accuracy                           0.36     14959\n",
      "   macro avg       0.22      0.19      0.18     14959\n",
      "weighted avg       0.37      0.36      0.33     14959\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_padded, test_labels)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "test_predictions = model.predict(test_padded)\n",
    "test_pred_labels = np.argmax(test_predictions, axis=1)\n",
    "test_true_labels = np.argmax(test_labels, axis=1)\n",
    "print(classification_report(test_true_labels, test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07c0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d5faba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
