{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e45ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47164aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"training.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1248c046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     im feeling rather rotten so im not very ambiti...      0\n",
       "1             im updating my blog because i feel shitty      0\n",
       "2     i never make her separate from me because i do...      0\n",
       "3     i left with my bouquet of red and yellow tulip...      1\n",
       "4       i was feeling a little vain when i did this one      0\n",
       "...                                                 ...    ...\n",
       "1995  i just keep feeling like someone is being unki...      3\n",
       "1996  im feeling a little cranky negative after this...      3\n",
       "1997  i feel that i am useful to my people and that ...      1\n",
       "1998  im feeling more comfortable with derby i feel ...      1\n",
       "1999  i feel all weird when i have to meet w people ...      4\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"test.csv\", encoding='latin-1')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c689da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_tokenized_lemmatized(tweet):\n",
    "    tweet = tweet.lower()                                                       #converting the text into lower\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)                                          #removing @mentions\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)                                          #removing hashtags\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)   #removing url          \n",
    "    tweet = re.sub(r'[^\\w\\s]','',tweet)                                         #removing punctuations\n",
    "    tweet = re.sub(r'\\d+', '', tweet)                                           #removing numbers\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet).strip()                                  #removing extra whitespaces  \n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stops = stopwords.words('english')\n",
    "    \n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    tokens = [t for t in tokens if not t in stops]\n",
    "    fintokens = []\n",
    "    for token in tokens:\n",
    "        fintokens.append(lemmatizer.lemmatize(token))\n",
    "    finaltext = \" \"\n",
    "    return finaltext.join(fintokens)\n",
    "\n",
    "for i in df_train.index:\n",
    "    string = df_train['text'][i]\n",
    "    preprostr = clean_tokenized_lemmatized(string)\n",
    "    df_train.at[i, 'text'] = preprostr\n",
    "\n",
    "for i in df_test.index:\n",
    "    preprostr = clean_tokenized_lemmatized(string)\n",
    "    df_test.at[i, 'text'] = preprostr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb03e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_detection(value):\n",
    "    if value == 0:\n",
    "        return \"sadness\"\n",
    "    elif value == 1:\n",
    "        return \"joy\"\n",
    "    elif value == 2:\n",
    "        return \"love\"\n",
    "    elif value == 3:\n",
    "        return \"anger\"\n",
    "    elif value == 4:\n",
    "        return \"fear\"\n",
    "df_train['emotion'] = df_train['label'].map(emotion_detection)\n",
    "df_test['emotion'] = df_test['label'].map(emotion_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ebd9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feel like wan na buy cute make see online even...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feel like wan na buy cute make see online even...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feel like wan na buy cute make see online even...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel like wan na buy cute make see online even...</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel like wan na buy cute make see online even...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>feel like wan na buy cute make see online even...</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>feel like wan na buy cute make see online even...</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>feel like wan na buy cute make see online even...</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>feel like wan na buy cute make see online even...</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>feel like wan na buy cute make see online even...</td>\n",
       "      <td>4</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  emotion\n",
       "0     feel like wan na buy cute make see online even...      0  sadness\n",
       "1     feel like wan na buy cute make see online even...      0  sadness\n",
       "2     feel like wan na buy cute make see online even...      0  sadness\n",
       "3     feel like wan na buy cute make see online even...      1      joy\n",
       "4     feel like wan na buy cute make see online even...      0  sadness\n",
       "...                                                 ...    ...      ...\n",
       "1995  feel like wan na buy cute make see online even...      3    anger\n",
       "1996  feel like wan na buy cute make see online even...      3    anger\n",
       "1997  feel like wan na buy cute make see online even...      1      joy\n",
       "1998  feel like wan na buy cute make see online even...      1      joy\n",
       "1999  feel like wan na buy cute make see online even...      4     fear\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be00186",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = ['joy', 'love']\n",
    "negative = ['sadness', 'fear', 'anger']\n",
    "def emotion_detection(value):\n",
    "    if value in positive:\n",
    "        return 1\n",
    "    elif value in negative:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "df_train['sentiment'] = df_train['emotion'].map(emotion_detection)\n",
    "df_test['sentiment'] = df_test['emotion'].map(emotion_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89ebc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.drop('emotion_n')\n",
    "#df_test.drop('emotion_n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70e508d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6066\n",
       "0    5216\n",
       "3    2434\n",
       "4    2149\n",
       "2    1482\n",
       "5     653\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b78818f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    695\n",
       "0    581\n",
       "3    275\n",
       "4    224\n",
       "2    159\n",
       "5     66\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "522d670e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    695\n",
       "0    581\n",
       "3    275\n",
       "4    224\n",
       "2    159\n",
       "5     66\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4245e701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6066\n",
       "0    5216\n",
       "3    2434\n",
       "4    2149\n",
       "2    1482\n",
       "5     653\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e68a332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f82c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range = (1, 3))),\n",
    "     ('SVM', LinearSVC())         \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03d6b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range = (1, 3))),\n",
    "     ('DT', DecisionTreeClassifier())         \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ae7b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range = (1, 3))),\n",
    "     ('NB', MultinomialNB())         \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "203646de",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range = (1, 3))),\n",
    "     ('NB', XGBClassifier())         \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8094b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer_bow', CountVectorizer(ngram_range=(1, 3))),\n",
       "                ('SVM', LinearSVC())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(df_train.text, df_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47c1a2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer_bow', CountVectorizer(ngram_range=(1, 3))),\n",
       "                ('DT', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(df_train.text, df_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f816bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer_bow', CountVectorizer(ngram_range=(1, 3))),\n",
       "                ('NB', MultinomialNB())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(df_train.text, df_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b49108d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer_bow', CountVectorizer(ngram_range=(1, 3))),\n",
       "                ('NB',\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               objective='multi:softprob', predictor=None, ...))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(df_train.text, df_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d50f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c2f62c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c88daa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emotion', 'label', 'sentiment', 'text'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_test) - set(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96f382f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       581\n",
      "           1       0.35      1.00      0.52       695\n",
      "           2       0.00      0.00      0.00       159\n",
      "           3       0.00      0.00      0.00       275\n",
      "           4       0.00      0.00      0.00       224\n",
      "           5       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.06      0.17      0.09      2000\n",
      "weighted avg       0.12      0.35      0.18      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c321049",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf2.predict(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3d5559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       581\n",
      "           1       0.35      1.00      0.52       695\n",
      "           2       0.00      0.00      0.00       159\n",
      "           3       0.00      0.00      0.00       275\n",
      "           4       0.00      0.00      0.00       224\n",
      "           5       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.06      0.17      0.09      2000\n",
      "weighted avg       0.12      0.35      0.18      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2f9b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf3.predict(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18ba73d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       581\n",
      "           1       0.35      1.00      0.52       695\n",
      "           2       0.00      0.00      0.00       159\n",
      "           3       0.00      0.00      0.00       275\n",
      "           4       0.00      0.00      0.00       224\n",
      "           5       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.06      0.17      0.09      2000\n",
      "weighted avg       0.12      0.35      0.18      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64b7af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf4.predict(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94349746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       581\n",
      "           1       0.35      1.00      0.52       695\n",
      "           2       0.00      0.00      0.00       159\n",
      "           3       0.00      0.00      0.00       275\n",
      "           4       0.00      0.00      0.00       224\n",
      "           5       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.06      0.17      0.09      2000\n",
      "weighted avg       0.12      0.35      0.18      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d9e34a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4525b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb697161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
